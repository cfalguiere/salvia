{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank using autoML and some data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Notebook Description\n",
    "\n",
    "**Dataset Reference:** https://archive.ics.uci.edu/ml/datasets/bank+marketing\n",
    "\n",
    "**Type of problem:** Classification\n",
    "\n",
    "**Type of solution:** AutoML + some data prep - generation of an ensembling model\n",
    "\n",
    "**Stack:**\n",
    "- pandas, numpy \n",
    "- SageMaker AutoML/AutoPilot\n",
    "- Studio's prebuilt image DataScience 3.0 (conda) and XGBoost Stack\n",
    "\n",
    "**Steps:**\n",
    "- download data\n",
    "- do some data preparation: compute 2 composite features remove some unimportant features \n",
    "- split and upmload datasets to s3\n",
    "- configure the automl job and run it \n",
    "- get the run information and analytics\n",
    "- download the model and reports (explainability and reports)\n",
    "- delete data and output generated on s3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install \"sagemaker>=2.121.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "import time\n",
    "\n",
    "run_id = f\"{strftime('%y%m%d%H%M', gmtime())}\"\n",
    "\n",
    "stage_prefix = \"L\"\n",
    "project_prefix = \"bank\"\n",
    "variant_prefix = \"automlwdp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_prefix_short = f\"{variant_prefix}/{run_id}\"\n",
    "job_prefix_long = f\"{stage_prefix}/{project_prefix}/{job_prefix_short}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"{job_prefix_short=}\")\n",
    "print(f\"{job_prefix_long=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "base_folder = os.path.join(\"./generated\", job_prefix_short)\n",
    "base_uri = f\"s3://{default_bucket}/{job_prefix_long}\"\n",
    "base_uri_for_jobs = f\"s3://{default_bucket}/{stage_prefix}-jobs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{base_folder=}\")\n",
    "print(f\"{base_uri=}\")\n",
    "print(f\"{base_uri_for_jobs=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_source_uri = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "\n",
    "data_folder = os.path.join(base_folder, \"data\")\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "raw_data_folder = os.path.join(data_folder, \"raw\")\n",
    "os.makedirs(raw_data_folder, exist_ok=True)\n",
    "\n",
    "response = urlopen(data_source_uri)\n",
    "source_zip = ZipFile(BytesIO(response.read()))\n",
    "source_zip.extractall(data_folder) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 10)         # Keep the output on one page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_folder = os.path.join(data_folder, \"bank-additional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.listdir(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_dataset_path = os.path.join(dataset_folder, \"bank-additional-full.csv\")\n",
    "df = pd.read_csv(raw_dataset_path, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['no_previous_contact'] = np.where(df['pdays'] == 999, 1, 0)                                 # Indicator variable to capture when pdays takes a value of 999\n",
    "df['not_working'] = np.where(np.in1d(df['job'], ['student', 'retired', 'unemployed']), 1, 0)   # Indicator for individuals not actively employed\n",
    "model_data = df                                                           # Convert categorical variables to sets of indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop\n",
    "model_data = model_data.drop(['duration', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split\n",
    "train_data, validation_data = np.split(\n",
    "#train_data, validation_data, test_data = np.split(\n",
    "    model_data.sample(frac=1, random_state=1729), \n",
    "    [int(0.8 * len(model_data))]\n",
    "    #[int(0.7 * len(model_data)), int(0.9*len(model_data))]\n",
    ")\n",
    "\n",
    "def save_dataset(df, prefix):\n",
    "    os.makedirs(os.path.join(data_folder, f\"{prefix}\"), exist_ok=True)\n",
    "    local_filename = os.path.join(data_folder, f\"{prefix}/{prefix}.csv\")\n",
    "    df.to_csv(local_filename, index=False, header=True)\n",
    "\n",
    "save_dataset(train_data, \"train\")\n",
    "save_dataset(validation_data, \"validation\")\n",
    "#save_dataset(test_data, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(data_folder, \"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(data_folder, \"validation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# uppload\n",
    "def upload_dataset(prefix):\n",
    "    local_filename = os.path.join(data_folder, f\"{prefix}/{prefix}.csv\")\n",
    "    uri = f\"{base_uri}/{prefix}\"\n",
    "    return sagemaker.s3.S3Uploader.upload(\n",
    "        local_path=local_filename,\n",
    "        desired_s3_uri=uri\n",
    "    )\n",
    "\n",
    "train_data_uri = upload_dataset(\"train\")\n",
    "validation_data_uri = upload_dataset(\"validation\")\n",
    "#test_data_uri = upload_dataset(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_data_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_data_uri)\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters\n",
    "\n",
    "TODO Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_candidates = 10\n",
    "validation_fraction = 0.2\n",
    "total_job_runtime_in_seconds = 1800\n",
    "\n",
    "label_column = \"y\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_name = job_prefix_long.replace(\"/\",\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"{job_name=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.automl.automl import AutoML\n",
    "from sagemaker.automl.automl import AutoMLInput\n",
    "from sagemaker.workflow.automl_step import AutoMLStep\n",
    " \n",
    "automl = AutoML(\n",
    "    role=role,\n",
    "    output_path=base_uri_for_jobs,\n",
    "    target_attribute_name=label_column,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    #total_job_runtime_in_seconds=total_job_runtime_in_seconds, \n",
    "    max_candidates = max_candidates,\n",
    "    mode=\"ENSEMBLING\"\n",
    ")\n",
    "\n",
    "input_training = AutoMLInput(\n",
    "    inputs=train_data_uri,\n",
    "    target_attribute_name=label_column,\n",
    "    channel_type=\"training\",\n",
    ")\n",
    "\n",
    "input_validation = AutoMLInput(\n",
    "    inputs=validation_data_uri,    \n",
    "    target_attribute_name=label_column,\n",
    "    channel_type=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "step_args = automl.fit(\n",
    "    inputs=[input_training, input_validation],\n",
    "    job_name=job_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the best candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#automl.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#automl.latest_auto_ml_job.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_candidate = automl.best_candidate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint(best_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(best_candidate['CandidateName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_candidate['InferenceContainers'][0]['ModelDataUrl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pprint(best_candidate['FinalAutoMLJobObjectiveMetric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pprint(best_candidate['CandidateProperties']['CandidateArtifactLocations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pprint(best_candidate['CandidateProperties']['CandidateMetrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pprint([ (metric['StandardMetricName'], metric['Value']) \n",
    "          for metric in best_candidate['CandidateProperties']['CandidateMetrics']\n",
    "       ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export best candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "model_output_folder = os.path.join(base_folder, \"model\")\n",
    "\n",
    "explainability_folder = os.path.join(model_output_folder, \"explainability\")\n",
    "os.makedirs(explainability_folder, exist_ok=True)\n",
    "\n",
    "explainability_uri = best_candidate['CandidateProperties']['CandidateArtifactLocations']['Explainability'] \n",
    "S3Downloader.download(s3_uri=explainability_uri,\n",
    "                      local_path=explainability_folder,\n",
    "                      sagemaker_session=sagemaker_session)\n",
    "\n",
    "model_insight_folder = os.path.join(model_output_folder, \"model-insight\")\n",
    "os.makedirs(model_insight_folder, exist_ok=True)\n",
    "\n",
    "model_insights_uri = best_candidate['CandidateProperties']['CandidateArtifactLocations']['ModelInsights'] \n",
    "S3Downloader.download(s3_uri=model_insights_uri,\n",
    "                      local_path=model_insight_folder,\n",
    "                      sagemaker_session=sagemaker_session)\n",
    "\n",
    "\n",
    "model_data_folder = os.path.join(model_output_folder, \"model-data\")\n",
    "os.makedirs(model_data_folder, exist_ok=True)\n",
    "\n",
    "model_data_uri = best_candidate['InferenceContainers'][0]['ModelDataUrl'] \n",
    "S3Downloader.download(s3_uri=model_data_uri,\n",
    "                      local_path=model_data_folder,\n",
    "                      sagemaker_session=sagemaker_session)\n",
    "\n",
    "print(f\"{model_output_folder=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "tar_filename = os.path.join(model_data_folder, \"model.tar.gz\")\n",
    "with tarfile.open(tar_filename, 'r') as archive:\n",
    "    archive.extractall(model_data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Delete local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "# Try to remove the local files; if it fails, throw an error using try...except.\n",
    "try:\n",
    "    shutil.rmtree(base_folder)\n",
    "except OSError as e:\n",
    "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Delete S3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO exception management\n",
    "s3 = boto3.Session(region_name = region).resource('s3')\n",
    "bucket = s3.Bucket(default_bucket)\n",
    "collection_to_be_deleted = bucket.object_versions.filter(Prefix=f\"{job_prefix_long}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pprint(list(collection_to_be_deleted.all()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deleted_keys = collection_to_be_deleted.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pprint([element['Deleted'] for element in deleted_keys])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Create Model Step to Create a Model\n",
    "\n",
    "In order to perform batch transformation using the example model, create a SageMaker model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "best_auto_ml_model = step_auto_ml_training.get_best_auto_ml_model(\n",
    "    role, \n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "step_args_create_model = best_auto_ml_model.create(\n",
    "    instance_type=instance_type_param\n",
    ")\n",
    "\n",
    "step_create_model = ModelStep(\n",
    "    name=\"AutoMLCreateModel\", \n",
    "    step_args=step_args_create_model\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Register Model Step to Create a Model Package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import ModelMetrics, MetricsSource\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=step_auto_ml_training.properties.BestCandidateProperties.ModelInsightsJsonReportPath,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    explainability=MetricsSource(\n",
    "        s3_uri=step_auto_ml_training.properties.BestCandidateProperties.ExplainabilityJsonReportPath,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "register_args = best_auto_ml_model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics\n",
    ")\n",
    "\n",
    "step_register = ModelStep(\n",
    "    name=\"AutoMLRegisterModel\", \n",
    "    step_args=register_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
