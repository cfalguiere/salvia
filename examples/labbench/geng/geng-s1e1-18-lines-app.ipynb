{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee83b6f-8759-4733-bae7-955d5829435b",
   "metadata": {},
   "source": [
    "# Generation G - S1E1 - 18 lines app\n",
    "\n",
    "This notebook is the companion of posts about Generative AI.\n",
    "\n",
    "This episode shows how to create a very simple app in 18 lines, and the implications of running this app, especially from the FinOps point of view."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17b8b2-9ac3-4d8f-817c-54b783d728c3",
   "metadata": {},
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5515b427-e2ce-49a5-8b98-b59498727f52",
   "metadata": {},
   "source": [
    "LangChain is a new open source framework that allows AI developers to combine Large Language Models (LLMs) with external data.\n",
    "\n",
    "LangChain resources\n",
    "> - Landpage: https://readthedocs.org/projects/langchain/db2d\n",
    "> - Comonents: https://docs.langchain.com/docs/category/components\n",
    "> - git: https://github.com/hwchase17/langchain.git\n",
    "> - API Reference: https://api.python.langchain.com/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eb4830-c223-4b49-afac-26a13b3b706a",
   "metadata": {},
   "source": [
    "## The 18 lines streamlit app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9df0f0-f579-4a04-b860-097aa089a76b",
   "metadata": {},
   "source": [
    "Let's start with the [basic LLM app in 18 lines of code from the \n",
    "streamlit documentation](https://blog.streamlit.io/langchain-tutorial-1-build-an-llm-powered-app-in-18-lines-of-code/)\n",
    "\n",
    "Here is the full app code. It is really minimalistic, a text box for the question, the response is displayed right below.\n",
    "\n",
    "```python\n",
    "import streamlit as st\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "st.title('ðŸ¦œðŸ”— Quickstart App')\n",
    "\n",
    "openai_api_key = st.sidebar.text_input('OpenAI API Key')\n",
    "\n",
    "def generate_response(input_text):\n",
    "  llm = OpenAI(temperature=0.7, openai_api_key=openai_api_key)\n",
    "  st.info(llm(input_text))\n",
    "\n",
    "with st.form('my_form'):\n",
    "  text = st.text_area('Enter text:', 'What are the three key pieces of advice for learning how to code?')\n",
    "  submitted = st.form_submit_button('Submit')\n",
    "  if not openai_api_key.startswith('sk-'):\n",
    "    st.warning('Please enter your OpenAI API key!', icon='âš ')\n",
    "  if submitted and openai_api_key.startswith('sk-'):\n",
    "    generate_response(text)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b024fe8e-6e19-44d0-aebd-3f7555c78e7a",
   "metadata": {},
   "source": [
    "## The app's interaction with OpenAI APIs\n",
    "\n",
    "The interaction with the model is located in the function __generate_response__. Does not seem to hard to workaround.\n",
    "\n",
    "```python\n",
    "def generate_response(input_text):\n",
    "    llm = OpenAI(temperature=0.7, openai_api_key=openai_api_key)\n",
    "    st.info(llm(input_text))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08ceae4-be11-4201-8377-1e735b7b1030",
   "metadata": {},
   "source": [
    "## notes for conclusion \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b198bd5-97e8-4943-ae31-85cac5698004",
   "metadata": {},
   "source": [
    "# Material"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a287d35-40f0-47cd-93af-a7326b03f167",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ede566-b351-4301-a2d6-2141a3b092aa",
   "metadata": {},
   "source": [
    "### Update environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f30f2f91-cc9a-42f9-9c77-972e72526e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://deb.debian.org/debian bullseye InRelease\n",
      "Hit:2 http://deb.debian.org/debian bullseye-updates InRelease\n",
      "Hit:3 http://security.debian.org/debian-security bullseye-security InRelease\n",
      "Reading package lists... Done\n"
     ]
    }
   ],
   "source": [
    "!apt-get update && apt-get install -y build-essential 1>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b81739d-58b1-4a53-831c-f12978f001f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://deb.debian.org/debian bullseye InRelease\n",
      "Hit:2 http://deb.debian.org/debian bullseye-updates InRelease\n",
      "Hit:3 http://security.debian.org/debian-security bullseye-security InRelease\n",
      "Reading package lists... Done\n"
     ]
    }
   ],
   "source": [
    "!apt-get update && apt-get install -y jq 1>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dde1920f-5820-4f4f-89ce-0cfc297f6854",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip  1>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a345dc0-c97e-4beb-b501-b4d573fb2ce6",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ac7587f-c5e7-423f-af34-d4189caa0be1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.0.230 1>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1a92f5a-0d75-42ad-9e41-74dd1e61cd68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.27.8 1>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7b049c0-eaf7-4d6e-b923-1a57a5974e95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken==0.4.0 1>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84479774-4a0f-4d3e-998f-8d23ba34cf30",
   "metadata": {},
   "source": [
    "## Secrets and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "006d1f64-ed18-4c4e-a4df-6f192488b8ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash --out secrets \n",
    "# using AWS's Secret Manager to store keys\n",
    "# garb the keys and store it into a Pytthon variable\n",
    "export RESPONSE=$(aws secretsmanager get-secret-value --secret-id 'salvia/labbench/tests' )\n",
    "export SECRETS=$( echo $RESPONSE | jq '.SecretString | fromjson')\n",
    "\n",
    "echo $SECRETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10065ce2-fbb0-4f51-9bc5-e3ef4d44dede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = eval(secrets)[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff0c66c-6183-4812-901e-34e3deff6ad6",
   "metadata": {},
   "source": [
    "## Code session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef6c36-a815-4fd6-aaeb-e519e527c3bb",
   "metadata": {},
   "source": [
    "change in generate_response\n",
    "\n",
    "```python\n",
    "def generate_response(input_text):\n",
    "    llm = get_llm_model()\n",
    "    st.info(llm(input_text))\n",
    "```\n",
    "\n",
    "Tests of the llm in isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b2831e-c170-476d-b020-7c0fcd4eb50a",
   "metadata": {},
   "source": [
    "Resources\n",
    "> - https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ea4a621-1b2b-493d-8d65-adecb0523dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 ms, sys: 4.7 ms, total: 14.7 ms\n",
      "Wall time: 42.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.llms.fake import FakeListLLM\n",
    "\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"] \n",
    "\n",
    "def get_llm_model():\n",
    "    llm = OpenAI(temperature=0.7, openai_api_key=openai_api_key)\n",
    "    return llm\n",
    "\n",
    "llm = get_llm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca7fff3e-ae56-4ac5-be2c-01a63f87b410",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseModel.json of OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.7, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all', tiktoken_model_name=None)>\n"
     ]
    }
   ],
   "source": [
    "llm_info = llm.json\n",
    "#print(llm_info)  # warning: disclose the apo key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41d37d3a-c219-48c9-ad2f-4dddb0747be4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max tokens response 256\n"
     ]
    }
   ],
   "source": [
    "print(f\"max tokens response {llm.max_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d1aff79-c6c7-4f58-aa43-63b3b312b459",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max tokens total 4097\n"
     ]
    }
   ],
   "source": [
    "print(f\"max tokens total {llm.max_context_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9103853-f6aa-43ff-8502-1b51ccf75513",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query tolens 8 - result tokens 21\n",
      "\n",
      "\n",
      "The average distance from Earth to the Moon is 238,855 miles (384,400 kilometers).\n",
      "CPU times: user 254 ms, sys: 53.7 ms, total: 307 ms\n",
      "Wall time: 2.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = \"What is the distance to the Moon?\"\n",
    "response = llm(query)\n",
    "print(f\"query tolens {llm.get_num_tokens(query)} - result tokens {llm.get_num_tokens(response)}\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25a9c7-a679-4d5a-994c-e13e01756b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_tokens(text: str) â†’ intÂ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d77582d1-1156-476b-8ea2-cb74c09c4b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query tolens 6 - result tokens 78\n",
      "\n",
      "\n",
      "The White Rabbit is a fictional character in Lewis Carroll's 1865 novel Alice's Adventures in Wonderland. The White Rabbit is constantly late and in a state of frenzied panic. He wears a waistcoat and carries a pocket watch. He is very worried about being late, and is often seen muttering to himself, \"Oh dear! Oh dear! I shall be too late!\"\n",
      "CPU times: user 6.43 ms, sys: 387 Âµs, total: 6.82 ms\n",
      "Wall time: 1.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = \"Who is the White Rabbit?\"\n",
    "response = llm(query)\n",
    "print(f\"query tolens {llm.get_num_tokens(query)} - result tokens {llm.get_num_tokens(response)}\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4d5e02-8f35-4f92-8071-2b12465f7a0f",
   "metadata": {},
   "source": [
    "\n",
    "To the question \"What is the distance to the Moon?\", we get the right answer:\n",
    "> \"The average distance from Earth to the Moon is 238,855 miles (384,400 kilometers)\".\n",
    "\n",
    "And to the question  \"Who is the White Rabbit?\", we get a typical ChatGPT answer:\n",
    "> The White Rabbit is a fictional character from the book Alice's Adventures in Wonderland by Lewis Carroll. He appears at the very beginning of the story, in which Alice follows him down a rabbit hole, and is noted for his continual use of the phrase \"Oh dear! Oh dear! I shall be too late!\" He is often referred to as the March Hare, due to his association with the March Hare in the book's sequel, Through the Looking-Glass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befaec12-f2a6-453f-b96c-b16731b3ac3f",
   "metadata": {},
   "source": [
    "## OpenAI usage \n",
    "\n",
    "https://platform.openai.com/account/usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b1337-8cf1-4f40-981d-35086d35161b",
   "metadata": {},
   "source": [
    "## AWS usage\n",
    "\n",
    "https://platform.openai.com/account/usage"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-3:615547856133:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
