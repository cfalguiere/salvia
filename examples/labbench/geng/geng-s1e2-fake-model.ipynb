{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee83b6f-8759-4733-bae7-955d5829435b",
   "metadata": {},
   "source": [
    "# Generation G - S1E2 - Fake model\n",
    "\n",
    "This notebook is the companion of posts about Generative AI.\n",
    "\n",
    "This episode shows how to replace the OpenAI lmm with a fake llm, and build a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08ceae4-be11-4201-8377-1e735b7b1030",
   "metadata": {},
   "source": [
    "## Concluson\n",
    "\n",
    "This option is for tests purpose only.\n",
    "The fake llm i dumb.\n",
    "\n",
    "However it is usefull to mimic the real model behavior and putputs for dev purpose.\n",
    "\n",
    "There are advantages during the development phase:\n",
    "- They are free. you don't have to pay for the rtrial and error steps.\n",
    "- The response is quite immediate while testing with real models requires API calls and may suffer fromlatency.\n",
    "- The model does not requires credentials and secret management\n",
    "- The response can be very deterministic if the random list make use of a seed\n",
    "\n",
    "They are a good fit for automated testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b198bd5-97e8-4943-ae31-85cac5698004",
   "metadata": {},
   "source": [
    "# Material"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a287d35-40f0-47cd-93af-a7326b03f167",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4604152f-f587-48d0-adf8-9a3f653c1fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Update environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30f2f91-cc9a-42f9-9c77-972e72526e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.debian.org/debian-security bullseye-security InRelease [48.4 kB]\n",
      "Hit:2 http://deb.debian.org/debian bullseye InRelease\n",
      "Hit:3 http://deb.debian.org/debian bullseye-updates InRelease\n",
      "Get:4 http://security.debian.org/debian-security bullseye-security/main amd64 Packages [252 kB]\n",
      "Fetched 300 kB in 0s (665 kB/s)   \n",
      "Reading package lists... Done\n"
     ]
    }
   ],
   "source": [
    "!apt-get update && apt-get install -y build-essential 1>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b81739d-58b1-4a53-831c-f12978f001f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://deb.debian.org/debian bullseye InRelease\n",
      "Hit:2 http://deb.debian.org/debian bullseye-updates InRelease\n",
      "Hit:3 http://security.debian.org/debian-security bullseye-security InRelease\n",
      "Reading package lists... Done\n"
     ]
    }
   ],
   "source": [
    "!apt-get update && apt-get install -y jq 1>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dde1920f-5820-4f4f-89ce-0cfc297f6854",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip  1>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a345dc0-c97e-4beb-b501-b4d573fb2ce6",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ac7587f-c5e7-423f-af34-d4189caa0be1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.0.230 1>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1a92f5a-0d75-42ad-9e41-74dd1e61cd68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.27.8 1>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fab024a-e49a-43b3-98bb-4d2bfd616a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken==0.4.0 1>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84479774-4a0f-4d3e-998f-8d23ba34cf30",
   "metadata": {},
   "source": [
    "## Secrets and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "006d1f64-ed18-4c4e-a4df-6f192488b8ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash --out secrets \n",
    "# using AWS's Secret Manager to store keys\n",
    "# garb the keys and store it into a Pytthon variable\n",
    "export RESPONSE=$(aws secretsmanager get-secret-value --secret-id 'salvia/labbench/tests' )\n",
    "export SECRETS=$( echo $RESPONSE | jq '.SecretString | fromjson')\n",
    "\n",
    "echo $SECRETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10065ce2-fbb0-4f51-9bc5-e3ef4d44dede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = eval(secrets)[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff0c66c-6183-4812-901e-34e3deff6ad6",
   "metadata": {},
   "source": [
    "## Code session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef6c36-a815-4fd6-aaeb-e519e527c3bb",
   "metadata": {},
   "source": [
    "change in the app and generate_response\n",
    "\n",
    "```python\n",
    "fake = True  # False\n",
    "\n",
    "def generate_response(input_text):\n",
    "    llm = get_fake_llm_model() if fake else get_llm_model()\n",
    "    st.info(llm(input_text))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ea4a621-1b2b-493d-8d65-adecb0523dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.llms.fake import FakeListLLM\n",
    "\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"] \n",
    "\n",
    "def get_llm_model():\n",
    "    llm = OpenAI(temperature=0.7, openai_api_key=openai_api_key)\n",
    "    return llm\n",
    "\n",
    "def get_fake_llm_model():\n",
    "    fake_responses = [\n",
    "        \"384,400 km\",\n",
    "        \"The White Rabbit is a character of Alice of Wonderland and is always late\"\n",
    "    ]\n",
    "    llm = FakeListLLM(responses=fake_responses) \n",
    "    return llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4007b9f-579e-47e9-b7e9-ad9151defe30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The average distance from Earth to the Moon is 238,855 miles (384,400 kilometers).\n",
      "\n",
      "\n",
      "The White Rabbit is a fictional character from Lewis Carroll's 1865 novel Alice's Adventures in Wonderland. He is a frantic, humanoid rabbit who is always late and in a hurry. He often talks to himself in a frenzied manner and is often seen to carry a pocket watch as he runs. He is known for his famous line, \"Oh dear! Oh dear! I shall be too late!\"\n",
      "CPU times: user 22.3 ms, sys: 7.68 ms, total: 30 ms\n",
      "Wall time: 3.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fake = False\n",
    "llm = get_fake_llm_model() if fake else get_llm_model()\n",
    "    \n",
    "query = \"What is the distance to the Moon?\"\n",
    "print(llm(query))\n",
    "\n",
    "query = \"Who is the White Rabbit?\"\n",
    "print(llm(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4d5e02-8f35-4f92-8071-2b12465f7a0f",
   "metadata": {},
   "source": [
    "Open AI gave the answers below.\n",
    "\n",
    "To the question \"What is the distance to the Moon?\", we get the right answer:\n",
    "> \"The average distance from Earth to the Moon is 238,855 miles (384,400 kilometers)\".\n",
    "\n",
    "And to the question  \"Who is the White Rabbit?\", we get a typical ChatGPT answer:\n",
    "> The White Rabbit is a fictional character from the book Alice's Adventures in Wonderland by Lewis Carroll. He appears at the very beginning of the story, in which Alice follows him down a rabbit hole, and is noted for his continual use of the phrase \"Oh dear! Oh dear! I shall be too late!\" He is often referred to as the March Hare, due to his association with the March Hare in the book's sequel, Through the Looking-Glass.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fb29f88-3eae-4472-9c59-80c3be74659c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384,400 km\n",
      "The White Rabbit is a character of Alice of Wonderland and is always late\n",
      "CPU times: user 1.39 ms, sys: 0 ns, total: 1.39 ms\n",
      "Wall time: 2.72 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fake = True\n",
    "llm = get_fake_llm_model() if fake else get_mlm_model()\n",
    "    \n",
    "query = \"What is the distance to the Moon?\"\n",
    "print(llm(query))\n",
    "\n",
    "query = \"Who is the White Rabbit?\"\n",
    "print(llm(query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37fc7a4a-0a93-4285-ae59-8a406a6978fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result in list index out of range if an extra query is placed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c945c3bc-223b-49c2-a498-ef1e081a6c18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    query = \"What is the Capital of France?\"\n",
    "    print(llm(query))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c28bbd-497a-43de-99d5-21fc0001c1cf",
   "metadata": {},
   "source": [
    "## QA dataset\n",
    "\n",
    "Hopefully NLP benchmarks have a similar need for large sets of answers and they curated datasets.\n",
    "\n",
    "Squad is a Question and answer dataset available as a JSON file. \n",
    "> - SQUAD page https://rajpurkar.github.io/SQuAD-explorer/\n",
    "> - SQUAD Dataset https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
    "> - other datasets https://paperswithcode.com/task/question-answering#:~:text=Popular%20benchmark%20datasets%20for%20evaluation%20question%20answering%20systems%20include%20SQuAD,models%20are%20T5%20and%20XLNet.\n",
    "\n",
    "The file structure is quite complex, however questions and answers are easy to find.\n",
    "Some elements to take into considération:\n",
    "    - The file has multiple areas. \n",
    "    - In each area, there are paragraphs consisting in a context, questions and answers.\n",
    "    - Most questions have multiple answers. However some are empty. \n",
    "    - Each answer tracks the start of the text occurence in the context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69d34659-c826-4f2d-a244-47fb6fbca77c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root level attributes dict_keys(['version', 'data'])\n",
      "number of areas 35\n",
      "area attributes dict_keys(['title', 'paragraphs'])\n",
      "paragraphs attributes dict_keys(['qas', 'context'])\n",
      "qas attributes dict_keys(['question', 'id', 'answers', 'is_impossible'])\n",
      "question sample In what country is Normandy located?\n",
      "answers attributes dict_keys(['text', 'answer_start'])\n",
      "answers attributes France\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json \n",
    "from pprint import pprint\n",
    "\n",
    "squad_dataset_path = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\"\n",
    "with urllib.request.urlopen(squad_dataset_path) as url:\n",
    "    data= json.load(url)\n",
    "\n",
    "print(f\"root level attributes {data.keys()}\")\n",
    "print(f\"number of areas {len(data['data'])}\")\n",
    "print(f\"area attributes {data['data'][0].keys()}\")\n",
    "print(f\"paragraphs attributes {data['data'][0]['paragraphs'][0].keys()}\")\n",
    "print(f\"qas attributes {data['data'][0]['paragraphs'][0]['qas'][0].keys()}\")\n",
    "print(f\"question sample {data['data'][0]['paragraphs'][0]['qas'][0]['question']}\")\n",
    "print(f\"answers attributes {data['data'][0]['paragraphs'][0]['qas'][0]['answers'][0].keys()}\")\n",
    "print(f\"answers attributes {data['data'][0]['paragraphs'][0]['qas'][0]['answers'][0]['text']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0a040a78-aa95-434f-991a-7fd8ddd82c98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['30–75%',\n",
      " 'the same procedures as for IPCC Assessment Reports',\n",
      " 'south',\n",
      " '32,463',\n",
      " 'normal faulting and through the ductile stretching and thinning',\n",
      " 'Construction',\n",
      " 'Brest',\n",
      " '14',\n",
      " 'Maria Skłodowska-Curie Institute of Oncology',\n",
      " 'the same procedures as for IPCC Assessment Reports',\n",
      " 'small-business proprietors',\n",
      " '2.5 million',\n",
      " 'NP-complete Boolean satisfiability problem',\n",
      " 'Thames River',\n",
      " 'colloblasts',\n",
      " 'evidence',\n",
      " 'between 1500 and 1850',\n",
      " 'an Eastern Bloc city',\n",
      " 'level of the top tax rate',\n",
      " 'Advanced Steam']\n"
     ]
    }
   ],
   "source": [
    "# randomly pick answers\n",
    "from random import randrange\n",
    "from pprint import pprint\n",
    "\n",
    "answers = []\n",
    "while len(answers) < 20:\n",
    "    a = randrange(len(data['data']))\n",
    "    p = randrange(len(data['data'][a]['paragraphs']))\n",
    "    q = randrange(len(data['data'][a]['paragraphs'][p]['qas']))\n",
    "    nr_t = len(data['data'][a]['paragraphs'][p]['qas'][q]['answers'])\n",
    "    if nr_t > 0:\n",
    "        t = randrange(nr_t)\n",
    "        answer = data['data'][a]['paragraphs'][p]['qas'][q]['answers'][0]['text']\n",
    "        answers.append(answer)\n",
    "\n",
    "pprint(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255093b9-77e9-44ea-a9d2-4f3ce51639c2",
   "metadata": {},
   "source": [
    "## Fake LLM with dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f43fbf42-b68f-4f66-82eb-2d31abd879ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.fake import FakeListLLM\n",
    "import urllib.request\n",
    "import json \n",
    "from random import randrange\n",
    "\n",
    "def get_responses(size):\n",
    "    # loads the dataset\n",
    "    squad_dataset_path = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\"\n",
    "    with urllib.request.urlopen(squad_dataset_path) as url:\n",
    "        data= json.load(url)\n",
    "\n",
    "    # randomly pick answers\n",
    "    answers = []\n",
    "    while len(answers) < size:\n",
    "        a = randrange(len(data['data']))\n",
    "        p = randrange(len(data['data'][a]['paragraphs']))\n",
    "        q = randrange(len(data['data'][a]['paragraphs'][p]['qas']))\n",
    "        nr_t = len(data['data'][a]['paragraphs'][p]['qas'][q]['answers'])\n",
    "        if nr_t > 0:\n",
    "            t = randrange(nr_t)\n",
    "            answer = data['data'][a]['paragraphs'][p]['qas'][q]['answers'][0]['text']\n",
    "            answers.append(answer)\n",
    "    print(answers)\n",
    "    return answers\n",
    "\n",
    "\n",
    "def get_fake_llm_model():\n",
    "    llm = FakeListLLM(responses=get_responses(20)) \n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccaf6bd9-59a6-45be-98bf-7b339f7eb896",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['final', 'regulates the practice of pharmacists and pharmacy technicians', 'though the 21st century', 'hormones', 'constituency seats', 'Civil disobedience', 'independent', 'Guilt implies wrong-doing', 'legitimacy of a particular law', 'Jacksonville', '3600', 'rent-seeking', 'nearly three hundred years', 'State Route 41', 'three', 'AUSTPAC was an Australian public X.25 network operated by Telstra', 'Japan', 'British troops', 'seven', '1565']\n",
      "final\n",
      "regulates the practice of pharmacists and pharmacy technicians\n",
      "though the 21st century\n",
      "hormones\n"
     ]
    }
   ],
   "source": [
    "llm = get_fake_llm_model() \n",
    "    \n",
    "for _ in range(4):\n",
    "    query = \"any\"\n",
    "    print(llm(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "465f8130-6e7f-4bea-aee3-98a7bf42932a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A user or host could call a host on a foreign network by including the DNIC of the remote network as part of the destination address', 'amount of time for which they are allowed to speak', 'northwest', 'oxygen-16', 'small numbers of settlers', 'Annual Status of Education Report', '12 million', 'two', 'Nearly 3,000', 'Timucua', 'The earlier they surrendered to the Mongols, the higher they were placed', 'a sword', 'governmental entities', 'surface condensers', 'statistical mechanics', '2018', 'College', 'much larger conflict between France and Great Britain', 'naval Battle of the Restigouche', 'in the relevant committee or committees']\n",
      "A user or host could call a host on a foreign network by including the DNIC of the remote network as part of the destination address\n",
      "amount of time for which they are allowed to speak\n",
      "northwest\n",
      "oxygen-16\n"
     ]
    }
   ],
   "source": [
    "llm = get_fake_llm_model() \n",
    "    \n",
    "for _ in range(4):\n",
    "    query = \"any\"\n",
    "    print(llm(query))"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-3:615547856133:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
